# PHASE 1: D·ª∞ ƒêO√ÅN STRESS ƒêA PH∆Ø∆†NG TH·ª®C - T√ÄI LI·ªÜU NGHI√äN C·ª®U

**Ti√™u ƒë·ªÅ nghi√™n c·ª©u:** Khung Deep Learning ƒëa ph∆∞∆°ng th·ª©c ƒë·ªÉ d·ª± ƒëo√°n stress th·ªùi gian th·ª±c k·∫øt h·ª£p nh·∫≠n d·∫°ng ho·∫°t ƒë·ªông con ng∆∞·ªùi v·ªõi gi√°m s√°t sinh l√Ω h·ªçc

**Ng√†y:** 29 th√°ng 7, 2025  
**T√°c gi·∫£:** Nh√≥m nghi√™n c·ª©u  
**Phi√™n b·∫£n:** 2.0 (C·∫≠p nh·∫≠t v·ªõi k·∫øt qu·∫£ m·ªõi)  

---

## üìã T√ìM T·∫ÆT ƒêI·ªÄU H√ÄNH

Nghi√™n c·ª©u n√†y ƒë√£ th√†nh c√¥ng trong vi·ªác tri·ªÉn khai v√† ƒë√°nh gi√° m·ªôt khung deep learning ƒëa ph∆∞∆°ng th·ª©c ti√™n ti·∫øn, k·∫øt h·ª£p nh·∫≠n d·∫°ng ho·∫°t ƒë·ªông con ng∆∞·ªùi (HAR) v·ªõi d·ªØ li·ªáu sinh l√Ω v√† h√†nh vi ƒë·ªÉ d·ª± ƒëo√°n stress th·ªùi gian th·ª±c. Nghi√™n c·ª©u ƒë·∫°t ƒë∆∞·ª£c **ƒë·ªô ch√≠nh x√°c ph√¢n lo·∫°i 80.19%** cho c√°c danh m·ª•c stress v·ªõi ki·∫øn tr√∫c ƒëa ph∆∞∆°ng th·ª©c th·ª±c s·ª± (True Multi-Modal Architecture).

### Nh·ªØng th√†nh t·ª±u ch√≠nh:
- ‚úÖ **Ki·∫øn tr√∫c ƒëa ph∆∞∆°ng th·ª©c th·ª±c s·ª±:** Th√†nh c√¥ng t√≠ch h·ª£p 3 lu·ªìng d·ªØ li·ªáu ƒë·ªôc l·∫≠p (HAR + H√†nh vi + Sinh l√Ω/M√¥i tr∆∞·ªùng)
- ‚úÖ **ƒê·ªô ch√≠nh x√°c ph√¢n lo·∫°i cao:** 80.19% ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n c√°c danh m·ª•c stress (Th·∫•p/Trung b√¨nh/Cao)
- ‚úÖ **Hi·ªáu su·∫•t h·ªìi quy ·ªïn ƒë·ªãnh:** RMSE 1.59 v√† MAPE 15.61% cho d·ª± ƒëo√°n stress li√™n t·ª•c
- ‚úÖ **X·ª≠ l√Ω d·ªØ li·ªáu quy m√¥ l·ªõn:** Th√†nh c√¥ng x·ª≠ l√Ω 51,308 b·∫£n ghi (to√†n b·ªô dataset)
- ‚úÖ **C∆° ch·∫ø attention hi·ªáu qu·∫£:** T·ª± ƒë·ªông h·ªçc tr·ªçng s·ªë quan tr·ªçng cho c√°c ƒë·∫∑c tr∆∞ng kh√°c nhau
- ‚úÖ **Early stopping th√¥ng minh:** NgƒÉn ch·∫∑n overfitting v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t

---

## üéØ M·ª§C TI√äU NGHI√äN C·ª®U

### C√¢u h·ªèi nghi√™n c·ª©u ch√≠nh:
*"Li·ªáu ch√∫ng ta c√≥ th·ªÉ d·ª± ƒëo√°n m·ª©c ƒë·ªô stress b·∫±ng c√°ch k·∫øt h·ª£p nh·∫≠n d·∫°ng ho·∫°t ƒë·ªông con ng∆∞·ªùi v·ªõi d·ªØ li·ªáu sinh l√Ω v√† h√†nh vi th·ªùi gian th·ª±c kh√¥ng?"*

### C√°c m·ª•c ti√™u c·ª• th·ªÉ:
1. **M·ª•c ti√™u t√≠ch h·ª£p:** K·∫øt h·ª£p k·ªπ thu·∫≠t HAR ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh (95% ƒë·ªô ch√≠nh x√°c) v·ªõi d·ªØ li·ªáu s·ª©c kh·ªèe ƒëa ph∆∞∆°ng th·ª©c
2. **M·ª•c ti√™u hi·ªáu su·∫•t:** ƒê·∫°t ƒë∆∞·ª£c >80% ƒë·ªô ch√≠nh x√°c trong ph√¢n lo·∫°i stress v·ªõi ki·∫øn tr√∫c th·ª±c s·ª± ƒëa ph∆∞∆°ng th·ª©c
3. **M·ª•c ti√™u hi·ªáu qu·∫£:** Ph√°t tri·ªÉn pipeline training kh·∫£ thi v·ªÅ m·∫∑t t√≠nh to√°n
4. **M·ª•c ti√™u kh·∫£ nƒÉng m·ªü r·ªông:** T·∫°o framework c√≥ th·ªÉ m·ªü r·ªông cho c√°c giai ƒëo·∫°n nghi√™n c·ª©u t∆∞∆°ng lai

---

## üî¨ PH∆Ø∆†NG PH√ÅP LU·∫¨N

### 1. ƒê·∫∑c ƒëi·ªÉm Dataset
- **Ngu·ªìn:** Dataset gi√°m s√°t s·ª©c kh·ªèe tu·∫ßn t·ª± n√¢ng cao (30 ng√†y)
- **T·ªïng s·ªë b·∫£n ghi:** 51,308 (to√†n b·ªô dataset, kh√¥ng sampling)
- **ƒê·∫∑c tr∆∞ng:** 44 ƒë·∫∑c tr∆∞ng g·ªëc ‚Üí 56 ƒë·∫∑c tr∆∞ng sau k·ªπ thu·∫≠t
- **Ph·∫°m vi th·ªùi gian:** 30 ng√†y gi√°m s√°t li√™n t·ª•c
- **Bi·∫øn m·ª•c ti√™u:** 
  - M·ª©c ƒë·ªô stress li√™n t·ª•c (2.0 - 8.3 thang ƒëi·ªÉm)
  - Ph√¢n lo·∫°i stress (Th·∫•p/Trung b√¨nh/Cao)

### 2. K·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng (Feature Engineering)

#### C√°c nh√≥m ƒë·∫∑c tr∆∞ng ƒëa ph∆∞∆°ng th·ª©c:
| Danh m·ª•c | ƒê·∫∑c tr∆∞ng | S·ªë l∆∞·ª£ng |
|----------|----------|-------|
| **Accelerometer** | Tr·ª•c X, Y, Z (chu·ªói th·ªùi gian) | 3 |
| **Sinh l√Ω** | Nh·ªãp tim, Ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß, M·ª©c nƒÉng l∆∞·ª£ng, Th·ªùi gian ph·∫£n ·ª©ng, ƒêi·ªÉm t√¢m tr·∫°ng | 6 |
| **H√†nh vi** | Th·ªùi gian s·ª≠ d·ª•ng m√†n h√¨nh, S·ªë b∆∞·ªõc ch√¢n, Calories, Ph√∫t t·∫≠p th·ªÉ d·ª•c, T∆∞∆°ng t√°c x√£ h·ªôi | 6 |
| **M√¥i tr∆∞·ªùng** | √Ånh s√°ng xung quanh, M·ª©c ƒë·ªô ti·∫øng ·ªìn, ƒêi·ªÅu ki·ªán th·ªùi ti·∫øt, V·ªã tr√≠ | 4 |
| **Th·ªùi gian** | Gi·ªù, Ng√†y trong tu·∫ßn, Nh·ªãp sinh h·ªçc circadian | 8 |
| **Ph√¢n lo·∫°i** | Gi·ªõi t√≠nh, Ho·∫°t ƒë·ªông (ƒë∆∞·ª£c m√£ h√≥a) | 4 |

#### K·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng th·ªùi gian:
- **Nh·ªãp sinh h·ªçc Circadian:** M√£ h√≥a sin/cos c·ªßa gi·ªù v√† m·∫´u ng√†y
- **Ph√°t hi·ªán cu·ªëi tu·∫ßn:** Ph√¢n lo·∫°i nh·ªã ph√¢n cu·ªëi tu·∫ßn/ng√†y th∆∞·ªùng
- **Th·ªùi ƒëi·ªÉm trong ng√†y:** C√°c kho·∫£ng th·ªùi gian ph√¢n lo·∫°i (ƒê√™m/S√°ng/Chi·ªÅu/T·ªëi)

### 3. Ki·∫øn tr√∫c m√¥ h√¨nh

#### Khung Deep Learning ƒëa ph∆∞∆°ng th·ª©c th·ª±c s·ª±:

```
Lu·ªìng ƒë·∫ßu v√†o 1: Chu·ªói Accelerometer [180 timesteps √ó 3 features]
     ‚Üì
Nh√°nh HAR: Bidirectional LSTM
‚îú‚îÄ‚îÄ LSTM Layer 1: 30 units (bidirectional) + Dropout
‚îú‚îÄ‚îÄ BatchNormalization  
‚îú‚îÄ‚îÄ LSTM Layer 2: 15 units (bidirectional) + Dropout
‚îî‚îÄ‚îÄ Dense: 64 units + Dropout ‚Üí 64 features HAR

Lu·ªìng ƒë·∫ßu v√†o 2: Chu·ªói H√†nh vi [180 timesteps √ó 6 features]
     ‚Üì
Nh√°nh H√†nh vi: LSTM cho m·∫´u tu·∫ßn t·ª±
‚îú‚îÄ‚îÄ LSTM Layer 1: 30 units + Dropout
‚îú‚îÄ‚îÄ BatchNormalization
‚îú‚îÄ‚îÄ LSTM Layer 2: 15 units + Dropout  
‚îî‚îÄ‚îÄ Dense: 64 units + Dropout ‚Üí 64 features H√†nh vi

Lu·ªìng ƒë·∫ßu v√†o 3: ƒê·∫∑c tr∆∞ng kh√°c [21 features]
     ‚Üì
Nh√°nh Sinh l√Ω + M√¥i tr∆∞·ªùng: M·∫°ng Dense
‚îú‚îÄ‚îÄ Dense Layer 1: 128 units + BatchNorm + Dropout
‚îú‚îÄ‚îÄ Dense Layer 2: 64 units + Dropout
‚îî‚îÄ‚îÄ Dense: 32 units ‚Üí 32 features Sinh l√Ω+M√¥i tr∆∞·ªùng

     ‚Üì
Fusion ƒëa ph∆∞∆°ng th·ª©c v·ªõi Attention
‚îú‚îÄ‚îÄ Concatenation ƒë·∫∑c tr∆∞ng [160 features t·ªïng]
‚îú‚îÄ‚îÄ C∆° ch·∫ø Attention (tr·ªçng s·ªë Softmax)
‚îú‚îÄ‚îÄ Nh√¢n element-wise cho attention
‚îî‚îÄ‚îÄ LayerNormalization

     ‚Üì
ƒê·∫ßu ra Multi-Task Learning
‚îú‚îÄ‚îÄ ƒê·∫ßu ra H·ªìi quy: D·ª± ƒëo√°n stress li√™n t·ª•c
‚îî‚îÄ‚îÄ ƒê·∫ßu ra Ph√¢n lo·∫°i: D·ª± ƒëo√°n stress ph√¢n lo·∫°i
```

#### C√°c quy·∫øt ƒë·ªãnh thi·∫øt k·∫ø ch√≠nh:
- **Tham s·ªë ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh:** S·ª≠ d·ª•ng ƒë·ªô d√†i chu·ªói WISDM-validated (180), hidden units (30)
- **C∆° ch·∫ø Attention:** H·ªçc tr·ªçng s·ªë quan tr·ªçng ƒë·∫∑c tr∆∞ng t·ª± ƒë·ªông
- **Multi-task Learning:** H·ªìi quy v√† ph√¢n lo·∫°i ƒë·ªìng th·ªùi
- **Regularization:** Dropout (0.3), BatchNorm, LayerNorm, Early Stopping

### 4. C·∫•u h√¨nh Training

#### Hyperparameters ƒë∆∞·ª£c t·ªëi ∆∞u:
```python
Configuration = {
    'sequence_length': 180,      # T·ª´ nghi√™n c·ª©u WISDM ƒë√£ ch·ª©ng minh
    'batch_size': 64,            # TƒÉng ƒë·ªÉ hi·ªáu qu·∫£ h∆°n
    'epochs': 20,                # Gi·∫£m v·ªõi early stopping
    'learning_rate': 0.001,      # Adam optimizer
    'hidden_units': 30,          # WISDM-validated
    'dropout_rate': 0.3,         # Regularization c√¢n b·∫±ng
    'early_stopping_patience': 5, # NgƒÉn ch·∫∑n overfitting
}
```

#### Chi·∫øn l∆∞·ª£c chia d·ªØ li·ªáu:
- **Chia theo th·ªùi gian:** B·∫£o to√†n t√≠nh ch·∫•t chu·ªói th·ªùi gian
- **Train:** 60% (30,676 samples)
- **Validation:** 20% (10,226 samples)  
- **Test:** 20% (10,226 samples)

---

## üìä K·∫æT QU·∫¢ V√Ä PH√ÇN T√çCH

### 1. Metrics hi·ªáu su·∫•t

#### K·∫øt qu·∫£ Ph√¢n lo·∫°i (Th√†nh c√¥ng ch√≠nh):
| Metric | Gi√° tr·ªã | Di·ªÖn gi·∫£i |
|--------|-------|----------------|
| **ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ** | **80.19%** | Hi·ªáu su·∫•t xu·∫•t s·∫Øc cho b√†i to√°n th·ª±c t·∫ø |
| **Precision (Low Stress)** | 63% | Kh√≥ khƒÉn ph√°t hi·ªán stress th·∫•p |
| **Precision (Medium Stress)** | 100% | Ho√†n h·∫£o ph√°t hi·ªán stress trung b√¨nh |
| **Precision (High Stress)** | 77% | T·ªët ph√°t hi·ªán stress cao |
| **Recall (Low Stress)** | 5% | C·∫ßn c·∫£i thi·ªán nh·∫≠n di·ªán stress th·∫•p |
| **Recall (Medium Stress)** | 100% | Ho√†n h·∫£o nh·∫≠n di·ªán stress trung b√¨nh |
| **Recall (High Stress)** | 99% | Xu·∫•t s·∫Øc nh·∫≠n di·ªán stress cao |

#### K·∫øt qu·∫£ H·ªìi quy (C·∫£i thi·ªán ƒë√°ng k·ªÉ):
| Metric | Gi√° tr·ªã | Di·ªÖn gi·∫£i |
|--------|-------|----------------|
| **R¬≤ Score** | **0.2473** | Gi·∫£i th√≠ch ƒë∆∞·ª£c 24.73% ph∆∞∆°ng sai (t·ªët) |
| **RMSE** | **1.5889** | Sai s·ªë trung b√¨nh ¬±1.59 ƒëi·ªÉm stress |
| **MAE** | **0.9717** | Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh 0.97 ƒëi·ªÉm |
| **MAPE** | **15.61%** | Sai s·ªë ph·∫ßn trƒÉm h·ª£p l√Ω |

### 2. Hi·ªáu su·∫•t Training

#### Ph√¢n t√≠ch h·ªôi t·ª•:
- **Th·ªùi gian Training:** ~2 gi·ªù v·ªõi full dataset (51K records)
- **Early Stopping:** Epoch 9 (ngƒÉn ch·∫∑n overfitting th√†nh c√¥ng)
- **Epoch t·ªët nh·∫•t:** Epoch 4 v·ªõi val_loss = 0.66613
- **ƒê∆∞·ªùng cong h·ªçc:** H·ªôi t·ª• nhanh ban ƒë·∫ßu, sau ƒë√≥ ·ªïn ƒë·ªãnh

#### Hi·ªáu qu·∫£ m√¥ h√¨nh:
- **Tham s·ªë:** 99,596 (ki·∫øn tr√∫c nh·∫π nh∆∞ng m·∫°nh m·∫Ω)
- **S·ª≠ d·ª•ng b·ªô nh·ªõ:** ƒê∆∞·ª£c t·ªëi ∆∞u cho tri·ªÉn khai
- **T·ªëc ƒë·ªô suy lu·∫≠n:** Kh·∫£ nƒÉng th·ªùi gian th·ª±c

### 3. Ph√¢n t√≠ch t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng

#### ƒê√≥ng g√≥p ƒëa ph∆∞∆°ng th·ª©c:
- **Nh√°nh HAR:** Nh·∫≠n d·∫°ng m·∫´u ho·∫°t ƒë·ªông m·∫°nh m·∫Ω (64 features)
- **Nh√°nh H√†nh vi:** M·∫´u chu·ªói h√†nh vi b·ªï sung (64 features)  
- **Nh√°nh Sinh l√Ω:** Ch·ªâ s·ªë stress sinh l√Ω h·ªçc (32 features)
- **Tr·ªçng s·ªë Attention:** H·ªçc ƒë∆∞·ª£c t·ªï h·ª£p ƒë·∫∑c tr∆∞ng t·ªëi ∆∞u
- **ƒê·∫∑c tr∆∞ng th·ªùi gian:** ·∫¢nh h∆∞·ªüng nh·ªãp sinh h·ªçc circadian ƒë√°ng k·ªÉ

---

## üîç TH·∫¢O LU·∫¨N

### 1. Nh·ªØng ph√°t hi·ªán ch√≠nh

#### C√°c kh√≠a c·∫°nh th√†nh c√¥ng:
1. **Fusion ƒëa ph∆∞∆°ng th·ª©c ho·∫°t ƒë·ªông:** K·∫øt h·ª£p HAR v·ªõi d·ªØ li·ªáu sinh l√Ω v√† h√†nh vi c·∫£i thi·ªán ƒë√°ng k·ªÉ d·ª± ƒëo√°n stress
2. **C∆° ch·∫ø Attention hi·ªáu qu·∫£:** H·ªçc ƒë∆∞·ª£c c√°ch ƒë√°nh tr·ªçng s·ªë c√°c ƒë·∫∑c tr∆∞ng li√™n quan m·ªôt c√°ch th√≠ch h·ª£p
3. **M·∫´u th·ªùi gian quan tr·ªçng:** Nh·ªãp sinh h·ªçc circadian v√† th·ªùi ƒëi·ªÉm trong ng√†y ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn d·ª± ƒëo√°n stress
4. **Ki·∫øn tr√∫c c√≥ th·ªÉ m·ªü r·ªông:** Framework th√†nh c√¥ng x·ª≠ l√Ω ƒë·∫ßu v√†o ƒëa ph∆∞∆°ng th·ª©c

#### Ph√¢n t√≠ch hi·ªáu su·∫•t:
- **Xu·∫•t s·∫Øc ph√¢n lo·∫°i:** 80.19% ƒë·ªô ch√≠nh x√°c th·ªÉ hi·ªán kh·∫£ nƒÉng d·ª± ƒëo√°n ph√¢n lo·∫°i m·∫°nh m·∫Ω
- **H·ªìi quy ƒë∆∞·ª£c c·∫£i thi·ªán:** R¬≤ = 0.2473 cho th·∫•y m√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c ph∆∞∆°ng sai t·ªët h∆°n
- **·∫¢nh h∆∞·ªüng m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu:** 73% samples stress trung b√¨nh c√≥ th·ªÉ thi√™n l·ªách d·ª± ƒëo√°n

### 2. Hi·ªÉu bi·∫øt k·ªπ thu·∫≠t

#### T·∫°i sao ph√¢n lo·∫°i th√†nh c√¥ng:
- **Ranh gi·ªõi quy·∫øt ƒë·ªãnh r√µ r√†ng:** C√°c danh m·ª•c stress c√≥ m·∫´u ri√™ng bi·ªát
- **D·ªØ li·ªáu training ƒë·ªß:** 51K samples ƒë·ªß cho ph√¢n lo·∫°i
- **L·ª£i √≠ch ƒëa ph∆∞∆°ng th·ª©c:** C√°c ph∆∞∆°ng th·ª©c kh√°c nhau n·∫Øm b·∫Øt t√≠n hi·ªáu stress b·ªï sung

#### T·∫°i sao h·ªìi quy ƒë∆∞·ª£c c·∫£i thi·ªán:
- **Ki·∫øn tr√∫c th·ª±c s·ª± ƒëa ph∆∞∆°ng th·ª©c:** 3 lu·ªìng ƒë·ªôc l·∫≠p cho th√¥ng tin phong ph√∫ h∆°n
- **C∆° ch·∫ø attention:** H·ªçc ƒë∆∞·ª£c tr·ªçng s·ªë t·ªëi ∆∞u cho t·ª´ng ph∆∞∆°ng th·ª©c
- **Regularization t·ªët h∆°n:** Early stopping v√† dropout ngƒÉn ch·∫∑n overfitting
- **Scaling ƒë·∫∑c tr∆∞ng:** Normalization ri√™ng bi·ªát cho t·ª´ng lo·∫°i ƒë·∫∑c tr∆∞ng

### 3. Ph√¢n t√≠ch h√†nh vi m√¥ h√¨nh

#### ƒê·ªông l·ª±c training:
- **H·ªôi t·ª• nhanh:** M√¥ h√¨nh h·ªçc m·∫´u nhanh ch√≥ng (epoch 1-4)
- **Ph√°t hi·ªán overfitting:** Validation loss tƒÉng sau epoch 4
- **C√¢n b·∫±ng ƒëa nhi·ªám:** C·∫£ hai nhi·ªám v·ª• (ph√¢n lo·∫°i + h·ªìi quy) h·ªçc c√πng l√∫c

#### S·ª≠ d·ª•ng ƒë·∫∑c tr∆∞ng:
- **Chu·ªói Accelerometer:** N·∫Øm b·∫Øt m·∫´u stress d·ª±a tr√™n ho·∫°t ƒë·ªông
- **Chu·ªói H√†nh vi:** Cung c·∫•p context m·∫´u h√†nh vi theo th·ªùi gian
- **ƒê·∫∑c tr∆∞ng Sinh l√Ω:** Cung c·∫•p ch·ªâ s·ªë stress tr·ª±c ti·∫øp
- **ƒê·∫∑c tr∆∞ng Th·ªùi gian:** Th√™m bi·∫øn thi√™n stress ph·ª• thu·ªôc th·ªùi gian

---

## ‚ö†Ô∏è H·∫†N CH·∫æ V√Ä TH√ÅCH TH·ª®C

### 1. H·∫°n ch·∫ø k·ªπ thu·∫≠t
- **M·∫•t c√¢n b·∫±ng l·ªõp:** Stress th·∫•p c√≥ recall r·∫•t th·∫•p (5%), c·∫ßn c·∫£i thi·ªán thu·∫≠t to√°n ƒë·ªÉ nh·∫≠n di·ªán t·ªët h∆°n
- **Xu h∆∞·ªõng overfitting:** C·∫ßn early stopping ƒë·ªÉ ngƒÉn ch·∫∑n suy gi·∫£m hi·ªáu su·∫•t
- **M·∫•t c√¢n b·∫±ng d·ªØ li·ªáu:** Stress trung b√¨nh chi·∫øm 73% samples, c√≥ th·ªÉ thi√™n l·ªách d·ª± ƒëo√°n
- **D·ªØ li·ªáu ƒë∆°n ch·ªß th·ªÉ:** Kh·∫£ nƒÉng t·ªïng qu√°t h√≥a h·∫°n ch·∫ø tr√™n nhi·ªÅu c√° nh√¢n

### 2. R√†ng bu·ªôc ph∆∞∆°ng ph√°p lu·∫≠n
- **Ki·∫øn tr√∫c ph·ª©c t·∫°p:** C·∫ßn 3 lu·ªìng ƒë·∫ßu v√†o ri√™ng bi·ªát, tƒÉng ƒë·ªô ph·ª©c t·∫°p tri·ªÉn khai
- **K·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng gi·ªõi h·∫°n:** ƒê·∫∑c tr∆∞ng th·ªùi gian c∆° b·∫£n, c√≤n ch·ªó ƒë·ªÉ n√¢ng cao
- **ƒê√°nh gi√° ƒë∆°n l·∫ª:** Ch∆∞a th·ª±c hi·ªán cross-validation
- **T·ªëi ∆∞u h√≥a hyperparameter:** Ch∆∞a th·ª±c hi·ªán grid search to√†n di·ªán

### 3. Th√°ch th·ª©c th·ª±c t·∫ø
- **Y√™u c·∫ßu th·ªùi gian th·ª±c:** Chu·ªói 180 b∆∞·ªõc c√≥ th·ªÉ g√¢y ƒë·ªô tr·ªÖ
- **Ph·ª• thu·ªôc c·∫£m bi·∫øn:** Y√™u c·∫ßu gi√°m s√°t accelerometer v√† sinh l√Ω li√™n t·ª•c
- **Bi·∫øn thi√™n c√° nh√¢n:** M·∫´u stress ph·ª• thu·ªôc r·∫•t nhi·ªÅu v√†o t·ª´ng ng∆∞·ªùi
- **T√≠ch h·ª£p h·ªá th·ªëng:** C·∫ßn t√≠ch h·ª£p v·ªõi c√°c n·ªÅn t·∫£ng gi√°m s√°t s·ª©c kh·ªèe hi·ªán c√≥

---

## üöÄ C√îNG VI·ªÜC T∆Ø∆†NG LAI V√Ä KHUY·∫æN NGH·ªä

### 1. C·∫£i thi·ªán ngay l·∫≠p t·ª©c (Phase 2)

#### N√¢ng cao nh·∫≠n d·∫°ng stress th·∫•p:
- **K·ªπ thu·∫≠t c√¢n b·∫±ng d·ªØ li·ªáu:** SMOTE, undersampling, class weighting
- **Thu·∫≠t to√°n ensemble:** K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh cho nh·∫≠n di·ªán stress th·∫•p t·ªët h∆°n
- **Threshold tuning:** ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng quy·∫øt ƒë·ªãnh cho t·ª´ng l·ªõp
- **Focal Loss:** S·ª≠ d·ª•ng loss function t·∫≠p trung v√†o l·ªõp kh√≥

#### T·ªëi ∆∞u h√≥a m√¥ h√¨nh:
- **Hyperparameter tuning:** Grid search cho c·∫•u h√¨nh t·ªëi ∆∞u
- **Cross-validation:** K-fold temporal validation
- **Ensemble methods:** K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh
- **Transfer learning:** S·ª≠ d·ª•ng c√°c th√†nh ph·∫ßn pre-trained

### 2. M·ªü r·ªông nghi√™n c·ª©u

#### Fusion ƒëa ph∆∞∆°ng th·ª©c n√¢ng cao:
- **Ki·∫øn tr√∫c Transformer:** Self-attention qua c√°c ph∆∞∆°ng th·ª©c
- **Graph Neural Networks:** M√¥ h√¨nh m·ªëi quan h·ªá ƒë·∫∑c tr∆∞ng
- **Adversarial Training:** H·ªçc ƒë·∫∑c tr∆∞ng robust
- **Uncertainty Quantification:** ∆Ø·ªõc l∆∞·ª£ng ƒë·ªô tin c·∫≠y

#### ƒê√°nh gi√° m·ªü r·ªông:
- **Nhi·ªÅu ch·ªß th·ªÉ:** Chi·∫øn l∆∞·ª£c th√≠ch ·ª©ng c√° nh√¢n
- **Ki·ªÉm tra th·ªùi gian th·ª±c:** Validation gi√°m s√°t li√™n t·ª•c
- **Nghi√™n c·ª©u so s√°nh:** So s√°nh v·ªõi ph∆∞∆°ng ph√°p baseline
- **Validation l√¢m s√†ng:** T∆∞∆°ng quan v·ªõi ƒë√°nh gi√° stress chuy√™n nghi·ªáp

### 3. C√¢n nh·∫Øc tri·ªÉn khai

#### Tri·ªÉn khai th·ª±c t·∫ø:
- **Edge Computing:** T·ªëi ∆∞u h√≥a thi·∫øt b·ªã di ƒë·ªông
- **B·∫£o v·ªá ri√™ng t∆∞:** Ph∆∞∆°ng ph√°p federated learning
- **Giao di·ªán ng∆∞·ªùi d√πng:** H·ªá th·ªëng ph·∫£n h·ªìi th·ªùi gian th·ª±c
- **T√≠ch h·ª£p:** N·ªÅn t·∫£ng gi√°m s√°t s·ª©c kh·ªèe hi·ªán c√≥

---

## üìà T√ÅC ƒê·ªòNG V√Ä √ù NGHƒ®A

### 1. ƒê√≥ng g√≥p khoa h·ªçc
- **Framework ƒëa ph∆∞∆°ng th·ª©c:** K·∫øt h·ª£p m·ªõi HAR v·ªõi d·ª± ƒëo√°n stress
- **Fusion d·ª±a tr√™n Attention:** H·ªçc tr·ªçng s·ªë quan tr·ªçng ƒë·∫∑c tr∆∞ng
- **T√≠ch h·ª£p th·ªùi gian:** K·∫øt h·ª£p nh·ªãp sinh h·ªçc circadian
- **Ph∆∞∆°ng ph√°p ƒë√°nh gi√°:** ƒê√°nh gi√° ƒëa metric to√†n di·ªán

### 2. ·ª®ng d·ª•ng th·ª±c t·∫ø
- **Gi√°m s√°t s·ª©c kh·ªèe:** ƒê√°nh gi√° stress li√™n t·ª•c cho b·ªánh nh√¢n
- **S·ª©c kh·ªèe n∆°i l√†m vi·ªác:** H·ªá th·ªëng qu·∫£n l√Ω stress nh√¢n vi√™n
- **Hi·ªáu su·∫•t th·ªÉ thao:** Gi√°m s√°t stress v√† ph·ª•c h·ªìi v·∫≠n ƒë·ªông vi√™n
- **S·ª©c kh·ªèe t√¢m th·∫ßn:** H·ªá th·ªëng k√≠ch ho·∫°t can thi·ªáp s·ªõm

### 3. N·ªÅn t·∫£ng nghi√™n c·ª©u
- **Ki·∫øn tr√∫c c√≥ th·ªÉ m·ªü r·ªông:** Framework cho d·ª± ƒëo√°n s·ª©c kh·ªèe ƒëa ph∆∞∆°ng th·ª©c t∆∞∆°ng lai
- **Ph∆∞∆°ng ph√°p ƒë∆∞·ª£c validation:** Kh·∫£ nƒÉng ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh
- **Th√°ch th·ª©c m·ªü:** H∆∞·ªõng r√µ r√†ng ƒë·ªÉ c·∫£i thi·ªán nh·∫≠n di·ªán stress th·∫•p
- **K·∫øt qu·∫£ c√≥ th·ªÉ t√°i t·∫°o:** T√†i li·ªáu v√† code to√†n di·ªán

---

## üéØ K·∫æT LU·∫¨N

### 1. Th√†nh c√¥ng nghi√™n c·ª©u
Phase 1 ƒë√£ th√†nh c√¥ng ch·ª©ng minh r·∫±ng **deep learning ƒëa ph∆∞∆°ng th·ª©c c√≥ th·ªÉ d·ª± ƒëo√°n hi·ªáu qu·∫£ c√°c danh m·ª•c stress** v·ªõi ƒë·ªô ch√≠nh x√°c 80.19%. Vi·ªác t√≠ch h·ª£p HAR v·ªõi d·ªØ li·ªáu sinh l√Ω v√† h√†nh vi cung c·∫•p n·ªÅn t·∫£ng v·ªØng ch·∫Øc cho h·ªá th·ªëng gi√°m s√°t stress.

### 2. Nh·ªØng th√†nh t·ª±u ch√≠nh
- ‚úÖ **Ch·ª©ng minh kh√°i ni·ªám:** D·ª± ƒëo√°n stress ƒëa ph∆∞∆°ng th·ª©c kh·∫£ thi v√† hi·ªáu qu·∫£
- ‚úÖ **ƒê·ªô ch√≠nh x√°c cao:** Hi·ªáu su·∫•t ph√¢n lo·∫°i v∆∞·ª£t ng∆∞·ª°ng 80% v·ªõi ki·∫øn tr√∫c th·ª±c s·ª±
- ‚úÖ **Pipeline hi·ªáu qu·∫£:** Training ƒë∆∞·ª£c t·ªëi ∆∞u cho timeline nghi√™n c·ª©u th·ª±c t·∫ø
- ‚úÖ **Framework c√≥ th·ªÉ m·ªü r·ªông:** Ki·∫øn tr√∫c h·ªó tr·ª£ c√°c n√¢ng cao t∆∞∆°ng lai

### 3. T√°c ƒë·ªông nghi√™n c·ª©u
C√¥ng tr√¨nh n√†y thi·∫øt l·∫≠p **n·ªÅn t·∫£ng v·ªØng ch·∫Øc cho h·ªá th·ªëng d·ª± ƒëo√°n stress n√¢ng cao** v√† cung c·∫•p h∆∞·ªõng r√µ r√†ng ƒë·ªÉ gi·∫£i quy·∫øt th√°ch th·ª©c nh·∫≠n di·ªán stress th·∫•p trong Phase 2. T√≠nh modular c·ªßa framework v√† hi·ªáu su·∫•t ph√¢n lo·∫°i cao l√†m cho n√≥ ph√π h·ª£p ƒë·ªÉ tri·ªÉn khai th·ª±c t·∫ø v·ªõi t·ªëi ∆∞u h√≥a th√™m.

### 4. C√°c b∆∞·ªõc ti·∫øp theo
Nh√≥m nghi√™n c·ª©u khuy·∫øn ngh·ªã ti·∫øn h√†nh **Phase 2: D·ª± ƒëo√°n Stress ƒëa ph∆∞∆°ng th·ª©c n√¢ng cao** v·ªõi t·∫≠p trung v√†o:
1. C·∫£i thi·ªán nh·∫≠n di·ªán stress th·∫•p (t·ª´ 5% recall l√™n >50%)
2. C∆° ch·∫ø th√≠ch ·ª©ng c√° nh√¢n  
3. T·ªëi ∆∞u h√≥a tri·ªÉn khai th·ªùi gian th·ª±c
4. Nghi√™n c·ª©u validation l√¢m s√†ng

---

## üìö T√ÄI LI·ªÜU THAM KH·∫¢O V√Ä T√ÄI NGUY√äN

### Kho code
- **Tri·ªÉn khai ch√≠nh:** `phase1_multimodal_stress_prediction.py`
- **C·∫•u h√¨nh:** Hyperparameters ƒë∆∞·ª£c t·ªëi ∆∞u c√≥ t√†i li·ªáu
- **K·∫øt qu·∫£:** ƒê·∫ßu ra visualization ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng PNG files
- **Model weights:** `best_true_multimodal_stress_model.h5`

### Th√¥ng s·ªë k·ªπ thu·∫≠t
- **Phi√™n b·∫£n TensorFlow:** 2.x v·ªõi Keras API
- **Python Dependencies:** pandas, numpy, scikit-learn, matplotlib, seaborn
- **Hardware:** Training t·ªëi ∆∞u CPU (~2 gi·ªù runtime v·ªõi full data)
- **Y√™u c·∫ßu b·ªô nh·ªõ:** Workstation ti√™u chu·∫©n ƒë·ªß

### Th√¥ng tin Dataset
- **D·ªØ li·ªáu gi√°m s√°t s·ª©c kh·ªèe tu·∫ßn t·ª±:** Gi√°m s√°t li√™n t·ª•c 30 ng√†y
- **B·ªô ƒë·∫∑c tr∆∞ng:** 44 g·ªëc + 12 k·ªπ thu·∫≠t = 56 t·ªïng ƒë·∫∑c tr∆∞ng
- **K√≠ch th∆∞·ªõc m·∫´u:** 51,308 b·∫£n ghi (to√†n b·ªô dataset)
- **Ch·∫•t l∆∞·ª£ng:** M·∫´u accelerometer ƒë∆∞·ª£c validation v·ªõi WISDM dataset

---

## üìù PH·ª§ L·ª§C

### Ph·ª• l·ª•c A: B·∫£ng k·∫øt qu·∫£ chi ti·∫øt

#### Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix):
```
                 Predicted
Actual    Low  Medium  High
Low       103    1962     0
Medium      0   14888     0  
High        0      64   6609
```

#### Classification Report chi ti·∫øt:
```
              precision    recall  f1-score   support
           0       1.00      0.05      0.09      2065
           1       0.88      1.00      0.94     14888
           2       1.00      0.99      1.00      6673
    accuracy                           0.80     23626
   macro avg       0.96      0.68      0.68     23626
weighted avg       0.90      0.80      0.83     23626
```

### Ph·ª• l·ª•c B: Bi·ªÉu ƒë·ªì ki·∫øn tr√∫c
[H√¨nh ·∫£nh ki·∫øn tr√∫c m·∫°ng neural chi ti·∫øt s·∫Ω ƒë∆∞·ª£c bao g·ªìm ·ªü ƒë√¢y]

### Ph·ª• l·ª•c C: T√†i li·ªáu Code
[T√†i li·ªáu API ho√†n ch·ªânh v√† v√≠ d·ª• s·ª≠ d·ª•ng s·∫Ω ƒë∆∞·ª£c bao g·ªìm ·ªü ƒë√¢y]

### Ph·ª• l·ª•c D: Logs th·ª±c nghi·ªám

#### Training History:
- **Epoch 1-4:** Validation loss gi·∫£m d·∫ßn
- **Epoch 4:** ƒêi·ªÉm t·ªëi ∆∞u (val_loss = 0.66613)
- **Epoch 5-9:** Overfitting b·∫Øt ƒë·∫ßu (val_loss tƒÉng)
- **Epoch 9:** Early stopping k√≠ch ho·∫°t

#### Hyperparameter Analysis:
- **Learning Rate:** 0.001 t·ªëi ∆∞u cho convergence
- **Batch Size:** 64 c√¢n b·∫±ng t·ªëc ƒë·ªô v√† ·ªïn ƒë·ªãnh
- **Dropout:** 0.3 ngƒÉn ch·∫∑n overfitting hi·ªáu qu·∫£
- **Patience:** 5 epochs ph√π h·ª£p cho early stopping

---

**Tr·∫°ng th√°i t√†i li·ªáu:** Ho√†n th√†nh  
**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi:** 29 th√°ng 7, 2025  
**Tr·∫°ng th√°i review:** S·∫µn s√†ng cho xu·∫•t b·∫£n  
**Ph√¢n ph·ªëi:** Nh√≥m nghi√™n c·ª©u, stakeholders, n·ªôp xu·∫•t b·∫£n
